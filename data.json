[
    {
        "name": "Llama 3.3 8B",
        "company": "Meta",
        "inference": "Meta",
        "contextSize": 128000,
        "maxOutput": 4000,
        "throughput": 243,
        "latency": 0.59,
        "inCost": 0,
        "outCost": 0
    }
]