<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="./styles.css" />
    <script>
      async function populateData(favs) {
        const models = "https://openrouter.ai/api/v1/models";

        // initialize data array
        let data = [];

        // attempt to fetch openrouter
        try {
          const openrouter = await fetch(models);
          if (!openrouter.ok) {
            throw new Error(`HTTP error: ${openrouter.status}`);
          }
          // destructure data from openrouter models response
          ({ data } = await openrouter.json());
        } catch (error) {
          console.log(`Failed: ${error}`);
          data = fallback;
        }

        const llms = [];
        data.map((item) => {
          const contextSize = Math.ceil(
            item.top_provider.context_length / 1000
          );
          let maxOutput = Math.ceil(
            item.top_provider.max_completion_tokens / 1000
          );
          if (maxOutput === 0) maxOutput = contextSize;
          const outCost = Math.round(item.pricing.completion * 100000000) / 100;
          const inCost = Math.round(item.pricing.prompt * 100000000) / 100;
          item.pricing.prompt * 1000000;
          llms.push({
            slug: item.id,
            contextSize,
            maxOutput,
            inCost,
            outCost,
          });
        });

        function insertData(tableName, query) {
          let selection = [];
          query.map((slug) => {
            const found = llms.find((llm) => llm.slug === slug);
            if (found) selection.push(found);
          });
          const tableBody = document.getElementById(tableName);
          // loop through every llm in selection
          selection.map((llm, index) => {
            const row = document.createElement("tr");
            row.classList.add("table__row");
            if (index % 2 != 0) row.classList.add("table__row--odd");
            // loop through values from llm
            Object.values(llm).map((value, index) => {
              // create link
              const link = document.createElement("a");

              // set target
              link.target = "_blank";

              // set href attribute
              link.href = "https://openrouter.ai/" + llm.slug;

              const cell = document.createElement("td");

              cell.classList.add("table__cell");

              if (index === 0) {
                // insert link
                link.append(value);
                // insert link into a cell
                cell.append(link);
              } else {
                // skip link insertion
                cell.append(value);
              }

              // insert every cell into a row
              row.append(cell);
            });
            // insert every row into the table body
            tableBody.append(row);
          });
        }

        insertData("agentic", [
          "amazon/nova-micro-v1",
          "meta-llama/llama-3.2-11b-vision-instruct",
          "mistralai/mistral-7b-instruct-v0.3",
          "liquid/lfm-7b",
          "qwen/qwen-2.5-7b-instruct",
          "cohere/command-r7b-12-2024",
          "google/gemini-2.0-flash-lite-001",
        ]);

        insertData("precise", [
          "x-ai/grok-4",
          "google/gemini-2.5-pro",
          "qwen/qwen3-235b-a22b-07-25",
          "deepseek/deepseek-chat-v3-0324",
          "moonshotai/kimi-k2",
          "deepseek/deepseek-r1-0528",
        ]);

        insertData("fast", [
          "qwen/qwen3-235b-a22b",
          "deepseek/deepseek-r1-distill-llama-70b",
          "meta-llama/llama-3.3-70b-instruct",
          "meta-llama/llama-4-maverick",
          "meta-llama/llama-4-scout",
          "meta-llama/llama-3.1-8b-instruct",
          "qwen/qwen3-32b",
        ]);
      }
    </script>
  </head>
  <body class="content" onload="populateData()">
    <article>
      <ol class="category">
        <li class="category__info">
          <h2 id="agents" class="category__title">
            Unexpensive quick responders
          </h2>

          <h3 class="category__suggestion">
            Click the following terms to learn their definitions.
          </h3>

          <details class="category__term">
            <summary>Throughput</summary>
            <p>
              Measured in <strong>tokens per second</strong> (tps). Is the
              average pace the AI write at.
            </p>
          </details>

          <details class="category__term">
            <summary>Latency</summary>
            <p>
              Measured in <strong>seconds</strong> (s). Is the average time the
              AI takes to start writing every answer.
            </p>
          </details>

          <details class="category__term">
            <summary>Size</summary>
            <p>
              Measured in <strong>Billions of parameters</strong> (B). Is
              representing of the size and complexity of the AI.
            </p>
          </details>

          <details class="category__term">
            <summary>Tool use</summary>
            <p>
              The capacity of an AI of querying systems, search the web, use
              apps and plugins made for them.
            </p>
          </details>

          <details class="category__term">
            <summary>Token</summary>
            <p>
              <strong>Essential unit of text</strong> no larger than a word.
              Punctuation marks and spaces might also count and some english
              words may use more than one token.
            </p>
          </details>

          <p class="category__explanation">
            This set of AI assistants combine a graceful throughput speed (100 -
            200tps), a verly low latency ( &lt; 0.5s ) and the best pricing at
            the platform starting as low as a single penny for 1 million tokens
            exchanged. They are very good answering questions and engaging in
            conversations. With any of these options you get instant smart
            responses and quick task creations at very low price. Their compact
            sizes from 7 to 11 Billions of parameters make them agile and very
            useful ...yet the whole world knowledge can't fit that network size
            so at very specific and niche topics they fail to imprecision
            <strong>if they can't access the right tool.</strong>
          </p>
        </li>

        <li class="category__info">
          <figure class="block block--scrollable">
            <table class="table">
              <thead>
                <tr class="table__row--heading">
                  <th class="table__cell" scope="col" rowspan="2">Link</th>
                  <th class="table__cell" scope="col" rowspan="2">
                    Context Size (K)
                  </th>
                  <th class="table__cell" scope="col" rowspan="2">
                    Max Output (K)
                  </th>
                  <th class="table__cell" scope="col" colspan="2">
                    Pricing (USD/1M)
                  </th>
                </tr>
                <tr class="table__row--heading">
                  <th class="table__cell" scope="col">Prompt</th>
                  <th class="table__cell" scope="col">Completion</th>
                </tr>
              </thead>
              <tbody id="agentic"></tbody>
            </table>
            <figcaption class="caption">
              Fast and cost-efficient AI Assistants.
            </figcaption>
          </figure>

          <h3 class="category__suggestion">
            Give them tools to make them sharper and more useful
          </h3>
          <p class="category__explanation">
            Is not very likey to have them accepting their
            <strong>lack of highly specific knowledge domain</strong> when it
            occurs so your platform better enforce the sourcing of adequate
            systems and the delegation of complex tasks to more specialized AI
            assistants when needed as these AI agents will almost never do it by
            themselves. Achieve that and you'll match the bigger and expensier
            AI with a smaller budget.
          </p>
        </li>
      </ol>
      <!-- end of agentic ai -->

      <ol class="category category--odd">
        <li class="category__info">
          <h2 id="smartest" class="category__title">Best ranked AI</h2>

          <h3 class="category__suggestion">
            Click the following terms to learn their definitions.
          </h3>

          <details class="category__term">
            <summary>GPQA</summary>
            Is the
            <strong>Graduate-Level Google-Proof Q&A Benchmark.</strong>
            Represents the AI accuracy solving ~500 very difficult questions
            through varios domains in science. The answers are validated by
            human experts.
          </details>

          <details class="category__term">
            <summary>Throughput</summary>
            <p>
              Measured in <strong>tokens per second</strong> (tps). Is the
              average pace the AI write at.
            </p>
          </details>

          <details class="category__term">
            <summary>Latency</summary>
            <p>
              Measured in <strong>seconds</strong> (s). Is the average time the
              AI takes to start writing every answer.
            </p>
          </details>

          <details class="category__term">
            <summary>Size</summary>
            <p>
              Measured in <strong>Billions of parameters</strong> (B). Is
              representing of the size and complexity of the AI.
            </p>
          </details>

          <details class="category__term">
            <summary>Tool use</summary>
            <p>
              The capacity of an AI of querying systems, search the web, use
              apps and plugins made for them.
            </p>
          </details>

          <details class="category__term">
            <summary>Token</summary>
            <p>
              <strong>Essential unit of text</strong> no larger than a word.
              Punctuation marks and spaces might also count and some english
              words may use more than one token.
            </p>
          </details>

          <details class="category__term">
            <summary>Provider</summary>
            <p>
              Represents the <strong>company</strong> runnning the AI model.
            </p>
          </details>

          <p class="category__explanation">
            Hundreds of billions of parameters delivers precise answers and
            solve exceptionally challenging tasks from specific scientific
            domains as they are tested by GPQA and they have also very rich
            comprehension of culture, history and other human areas of
            expertise. The absolute leaders of the AI rankings are in this list.
            Advanced AI applications implement them as the very default AI
            assistant in part to inflate their monthly fee because much of our
            questions can be easily solved by any of the models from the first
            list and even faster.
            <strong>Yes!</strong> These models being humongous as they are they
            struggle to surpass 100tps. And have you seen the fee yet?
            <strong>These are any cheap.</strong>
          </p>
        </li>
        <li class="category__info">
          <figure class="block block--scrollable">
            <table class="table">
              <thead>
                <tr class="table__row--heading">
                  <th class="table__cell" scope="col" rowspan="2">Link</th>
                  <th class="table__cell" scope="col" rowspan="2">
                    Context Size (K)
                  </th>
                  <th class="table__cell" scope="col" rowspan="2">
                    Max Output (K)
                  </th>
                  <th class="table__cell" scope="col" colspan="2">
                    Pricing (USD/1M)
                  </th>
                </tr>
                <tr class="table__row--heading">
                  <th class="table__cell" scope="col">Prompt</th>
                  <th class="table__cell" scope="col">Completion</th>
                </tr>
              </thead>
              <tbody id="precise"></tbody>
            </table>
            <figcaption class="caption">Smartest AI Assistants.</figcaption>
          </figure>

          <h3 class="category__suggestion">
            Pullising words to make more with less
          </h3>
          <p class="category__explanation">
            <strong>Multi-layer</strong> has been implemented as early as 2023
            and big AI players are just about to get an important update to make
            switching between huge models and agents easier and more
            comfortable. Instead of making the huge AI your agent and slow down
            the early stages of any task. Make it do the finnal touch and you'll
            not only save money you'll get things done faster. At the platform
            you'll find different providers to balance cost and throughput speed
            according your requirements.
          </p>
        </li>
      </ol>
      <!-- end of precise ai -->

      <ol class="category">
        <li class="category__info">
          <h2 id="fastest" class="category__title">Top of speed task force</h2>

          <h3 class="category__suggestion">
            Click the following terms to learn their definitions.
          </h3>

          <details class="category__term">
            <summary>Throughput</summary>
            <p>
              Measured in <strong>tokens per second</strong> (tps). Is the
              average pace the AI write at.
            </p>
          </details>

          <details class="category__term">
            <summary>Latency</summary>
            <p>
              Measured in <strong>seconds</strong> (s). Is the average time the
              AI takes to start writing every answer.
            </p>
          </details>

          <details class="category__term">
            <summary>Size</summary>
            <p>
              Measured in <strong>Billions of parameters</strong> (B). Is
              representing of the size and complexity of the AI.
            </p>
          </details>

          <details class="category__term">
            <summary>Token</summary>
            <p>
              <strong>Essential unit of text</strong> no larger than a word.
              Punctuation marks and spaces might also count and some english
              words may use more than one token.
            </p>
          </details>

          <details class="category__term">
            <summary>Provider</summary>
            <p>
              Represents the <strong>company</strong> runnning the AI model.
            </p>
          </details>

          <p class="category__explanation">
            Unmatched speed is what caracterizes this list. With values from 900
            and as high as ten thousand tokens per second. This group definitely
            has the speed record. They could write books in minutes. That's the
            fairest comparison.
            <strong
              >Quality is not impacted because of the speed but price
              is.</strong
            >
            The smaller models are even cheap yet as their size scalates the
            pricing does it also. You can have monumentally large AI running at
            high speed yet you will have to pay for such a miracle
          </p>
        </li>

        <li class="category__info">
          <figure class="block block--scrollable">
            <table class="table">
              <thead>
                <tr class="table__row--heading">
                  <th class="table__cell" scope="col" rowspan="2">Link</th>
                  <th class="table__cell" scope="col" rowspan="2">
                    Context Size (K)
                  </th>
                  <th class="table__cell" scope="col" rowspan="2">
                    Max Output (K)
                  </th>
                  <th class="table__cell" scope="col" colspan="2">
                    Pricing (USD/1M)
                  </th>
                </tr>
                <tr class="table__row--heading">
                  <th class="table__cell" scope="col">Prompt</th>
                  <th class="table__cell" scope="col">Completion</th>
                </tr>
              </thead>
              <tbody id="fast"></tbody>
            </table>
            <figcaption class="caption">
              Lightning-fast AI assistants.
            </figcaption>
          </figure>

          <h3 class="category__suggestion">Give detailed instructions</h3>
          <p class="category__explanation">
            In this list are AI assistants as large as 400 billions of
            parameters making it a certainty they will be useful at tasks with
            any level of complexity just as good as the ones from the previous
            list.
          </p>
        </li>
      </ol>
    </article>
    <aside class="float">
      <nav>
        <ul class="menu">
          <li>
            <a class="menu__link" href="#agents">Agents</a>
          </li>
          <li>
            <a class="menu__link" href="#smartest">Smartest</a>
          </li>
          <li>
            <a class="menu__link" href="#fastest">Fastest</a>
          </li>
        </ul>
      </nav>
    </aside>
    <footer class="footer">&copy; Copyright 2025 Martin Rojas</footer>
  </body>
</html>
